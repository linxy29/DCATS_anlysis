---
title: "Simulation_plus5"
author: "Xinyi Lin"
date: "11/11/2020"
output: html_document
---

Following steps will be done in this files:

1. extract parameters from a better real_word data. Sample GSM4878537(https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4878537)

2. Use splatter to generate a large cells pool.

3. Use Dirichlet Distribution to generate 100/1000 proportions vectors and selected cell clusters with related proportions.

4 Use Seurat(or other clusering methods) to do reclustering.

* Start from a lower sample sizes(1000)?

* build an automatic process to define resolution

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r,message=FALSE,warning=FALSE}
library(splatter)
library(Seurat)
library(speckle)
library(DCATS)
library(ggplot2)
library(tidyverse)
library(diffcyt)
library(MCMCpack)
```

```{r}
source("functionsV2.r")
```

```{r}
cluster_num = 3
probNor = c(1/3, 1/3, 1/3)
probMut = c(1/3, 1/2, 1/6)
sample_size = 1000 # sample size for each simulation
magnitude = 50 # indicate how simulated proportion far away from true, the larger the closer
```

## Simulate cells pool

```{r}
set.seed(123)
prob = c(1/3, 1/3, 1/3)
batch_size = 10000
de_prob = runif(3, 0.1, 0.6)
setresolu = 0.2
```

```{r}
set.seed(123)
params = readRDS("./data/ovarian_params.rds")
params = readRDS("./data/mnnCT7params.rds")
param.groups <- setParams(params, batchCells = batch_size, nGenes = 1000)
sim <- splatSimulateGroups(param.groups, group.prob = prob, de.prob = de_prob, verbose = FALSE)
sim_mat <- counts(sim)
origLabels = sim@colData@listData$Group
```


## simulate proportions

```{r}
set.seed(123)
proporNor = rdirichlet(10, probNor*magnitude)
proporMut = rdirichlet(10, probMut*magnitude)
print(proporNor)
print(proporMut)
```

## Select cells for each simulation and do the test(one time)

Cells selection

```{r, eval=FALSE}
# simulate cells numbers
set.seed(123)
i = 1
cell_numNor = (sample_size*proporNor[i,]) %>% ceiling()
cell_numMut = (sample_size*proporMut[i,]) %>% ceiling()
## condition 1
group1_idx = c(1:length(origLabels))[origLabels == "Group1"] %>% sample(cell_numNor[1])
group2_idx = c(1:length(origLabels))[origLabels == "Group2"] %>% sample(cell_numNor[2])
group3_idx = c(1:length(origLabels))[origLabels == "Group3"] %>% sample(cell_numNor[3])
indexNor = c(group1_idx, group2_idx, group3_idx) %>% sort()
summary(indexNor)
simNor_mat = sim_mat[,indexNor]
origLabelsNor = origLabels[indexNor]
## condition 2
group1_idx = c(1:length(origLabels))[origLabels == "Group1"] %>% sample(cell_numMut[1])
group2_idx = c(1:length(origLabels))[origLabels == "Group2"] %>% sample(cell_numMut[2])
group3_idx = c(1:length(origLabels))[origLabels == "Group3"] %>% sample(cell_numMut[3])
indexMut = c(group1_idx, group2_idx, group3_idx) %>% sort()
summary(indexMut)
simMut_mat = sim_mat[,indexMut]
origLabelsMut = origLabels[indexMut]
```

```{r}
i = 1
cell_sltL = cellSelect(sim_mat, origLabels, proporNor[i,], proporMut[i,], sample_size)
```

Seurat

```{r}
# set input
simNor_mat = cell_sltL$simNor_mat
simMut_mat = cell_sltL$simMut_mat

# pre-process
seuratNor <- CreateSeuratObject(counts = simNor_mat, project="Splatter")
seuratNor <- AddMetaData(object = seuratNor, metadata = rep("Normal", dim(simNor_mat)[2]), col.name = 'condition')
seuratMut <- CreateSeuratObject(counts = simMut_mat, project="Splatter")
seuratMut <- AddMetaData(object = seuratMut, metadata = rep("Mutate", dim(simNor_mat)[2]), col.name = 'condition')

listSamples = list(normal = seuratNor, mutate = seuratMut)
# log-normalization and identify variable features
for (i in 1:length(listSamples)) {
  listSamples[[i]] <- NormalizeData(listSamples[[i]], verbose = FALSE)
  listSamples[[i]] <- FindVariableFeatures(listSamples[[i]], selection.method = "vst", nfeatures = 2000, verbose = FALSE)
  }
  
# integrate all batches
anchors <- FindIntegrationAnchors(object.list = listSamples, dims = 1:30, verbose = FALSE)
integratedSamples <- IntegrateData(anchorset = anchors, dims = 1:30, verbose = FALSE)
DefaultAssay(integratedSamples) <- "integrated"

# clustering
integratedSamples <- ScaleData(integratedSamples, verbose = FALSE)
integratedSamples <- RunPCA(integratedSamples, npcs = 30, verbose = FALSE)
integratedSamples <- FindNeighbors(integratedSamples, dims = 1:30, verbose = FALSE)
integratedSamples <- FindClusters(integratedSamples, resolution = setresolu, algorithm=2, verbose = FALSE)
integratedSamples <- RunUMAP(integratedSamples, reduction = "pca", dims = 1:30, verbose = FALSE)

# change labels to A, B, C
integratedSamples@active.ident = integratedSamples@active.ident %>% 
  #plyr::mapvalues(from = c("0", "1", "2", "3", "4", "5"), to = c("A", "B", "C", "D", "E", "F"))
  plyr::mapvalues(from = c(0:11), to = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"))

plot = DimPlot(integratedSamples, reduction = "umap", split.by = "condition") + ggtitle("Cluster Results of Different Clusters in Different Samples")
print(plot)
```

```{r}
integratedSamples = runSeurat(cell_sltL, setresolu)
plot = DimPlot(integratedSamples, reduction = "umap", split.by = "condition") + ggtitle("Cluster Results of Different Clusters in Different Samples")
print(plot)
conf.mat<-table(Idents(integratedSamples), c(cell_sltL$origLabelsNor, cell_sltL$origLabelsMut))
print(conf.mat)
```

Test process

```{r}
condNor = integratedSamples@active.ident[integratedSamples$condition == "Normal"]
condMut = integratedSamples@active.ident[integratedSamples$condition == "Mutate"]
countNor = table(condNor)
countMut = table(condMut)
```


Need some replicates to get one group of p-values??????????

```{r}
## DCATS---betabinLRT
betabin_noM = betabinLRT_rw(countNor, countMut, bias_corr = FALSE)
print(betabin_noM)
##  DCATS---betabinLRT with Bias correction from similarity matrix
simil_matI = get_similarity_mat(length(probNor), confuse_rate=0)
simil_matU = get_similarity_mat(length(probNor), confuse_rate=0.1)
betabin_wMI = betabinLRT_rw(countNor, countMut, bias_corr = TRUE, similarity_mat = simil_matI)
print(betabin_wMI)
betabin_wMU = betabinLRT_rw(countNor, countMut, bias_corr = TRUE, similarity_mat = simil_matU)
print(betabin_wMU)
```

```{r}
##  DCATS---betabinLRT with Bias correction from similarity matrix
countNor_latent = countNor
countMut_latent = countMut
for (i in seq_len(nrow(countNor))) {
  countNor_latent[i, ] <- sum(countNor[i, ]) * multinom_EM(countNor[i, ], similarity_mat, verbose = FALSE)$mu
  }
for (i in seq_len(nrow(countMut))) {
  countMut_latent[i, ] <- sum(countMut[i, ]) * multinom_EM(countMut[i, ], similarity_mat, verbose = FALSE)$mu
  }
```


It should be a for loop here, 



## Codes

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```