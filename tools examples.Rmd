---
title: "tools example"
author: "Xinyi Lin"
date: "9/10/2020"
output: html_document
---

## speckle

```{r,message=FALSE,warning=FALSE}
library(speckle)
library(limma)
library(ggplot2)
library(tidyverse)
```

>In order to test for differences in cell type proportions between multiple experimental conditions at least one of the groups must have some form of biological replication (i.e. at least two samples). For a two group scenario, the absolute minimum sample size is thus three. Since there are many technical aspects which can affect cell type proportion estimates, having biological replication is essential for a meaningful analysis.

```{r,message=FALSE}
# Get some example data which has two groups, three cell types and two 
# biological replicates in each group
cell_info <- speckle_example_data()
head(cell_info)
cell_info %>% 
  group_by(clusters, samples, group) %>% 
  summarise(n = n())
```

```{r}
# Run propeller testing for cell type proportion differences between the two 
# groups
propeller(clusters = cell_info$clusters, sample = cell_info$samples, 
group = cell_info$group)

# Plot cell type proportions
plotCellTypeProps(clusters=cell_info$clusters, sample=cell_info$samples)
```

create my own examples

```{r}
myExample = data.frame(clusters = cell_info$clusters, groups = cell_info$group)
head(myExample)
propeller(clusters = myExample$clusters, group = myExample$groups)
```

## diffcyt

>The diffcyt package implements statistical methods for differential discovery analyses in high-dimensional cytometry data, based on a combination of high-resolution clustering and empirical Bayes moderated tests adapted from transcriptomics.

```{r,warning=FALSE}
library(HDCytoData)
library(flowCore)
library(diffcyt)
```

Load Data

```{r}
# d_flowSet
d_flowSet <- Bodenmiller_BCR_XL_flowSet()
print(d_flowSet)
```

what this `d_flowSet` looks like

```{r}
# sample names
pData(d_flowSet)
# number of cells
fsApply(d_flowSet, nrow)
# dimensions
dim(exprs(d_flowSet[[1]]))
# expression values
exprs(d_flowSet[[1]])[1:6, 1:5]
```

```{r}
# Meta-data: experiment information

# check sample order
filenames <- as.character(pData(d_flowSet)$name)

# sample information
sample_id <- gsub("^PBMC8_30min_", "", gsub("\\.fcs$", "", filenames))
group_id <- factor(
  gsub("^patient[0-9]+_", "", sample_id), levels = c("Reference", "BCR-XL")
)
patient_id <- factor(gsub("_.*$", "", sample_id))

experiment_info <- data.frame(
  group_id, patient_id, sample_id, stringsAsFactors = FALSE
)

print(experiment_info)
```

```{r}
# Meta-data: marker information

# source: Bruggner et al. (2014), Table 1

# column indices of all markers, lineage markers, and functional markers
cols_markers <- c(3:4, 7:9, 11:19, 21:22, 24:26, 28:31, 33)
cols_lineage <- c(3:4, 9, 11, 12, 14, 21, 29, 31, 33)
cols_func <- setdiff(cols_markers, cols_lineage)

# channel and marker names
channel_name <- colnames(d_flowSet)
marker_name <- gsub("\\(.*$", "", channel_name)

# marker classes
# note: using lineage markers for 'cell type', and functional markers for 
# 'cell state'
marker_class <- rep("none", ncol(d_flowSet[[1]]))
marker_class[cols_lineage] <- "type"
marker_class[cols_func] <- "state"
marker_class <- factor(marker_class, levels = c("type", "state", "none"))

marker_info <- data.frame(
  channel_name, marker_name, marker_class, stringsAsFactors = FALSE
)

print(marker_info)
```

```{r}
# Create design matrix
# note: selecting columns containing group IDs and patient IDs (for an 
# unpaired dataset, only group IDs would be included)
design <- createDesignMatrix(
  experiment_info, cols_design = c("group_id", "patient_id")
)
```

## Set up contrast matrix 

```{r}
# Create contrast matrix
contrast <- createContrast(c(0, 1, rep(0, 7)))

# check
nrow(contrast) == ncol(design)

data.frame(parameters = colnames(design), contrast)
```

## Individual functions

```{r}
# Prepare data
d_se <- prepareData(d_flowSet, experiment_info, marker_info)
# Transform data
d_se <- transformData(d_se)
# Generate clusters
# note: include random seed for reproducible clustering
d_se <- generateClusters(d_se, seed_clustering = 123)
# Calculate cluster cell counts
d_counts <- calcCounts(d_se)
# Calculate cluster medians
d_medians <- calcMedians(d_se)
```

```{r}
res_DA <- testDA_edgeR(d_counts, design, contrast)
```

The `testDA_edgeR` function is used for DAT. First, we need to get input object `SummarizedExperiment`

```{r}
nrows <- 200; ncols <- 6
counts <- matrix(runif(nrows * ncols, 1, 1e4), nrows)
item1 = rep(c("chr1", "chr2"), c(50, 150)) # 50 chr1 and 150 chr2
item2 = floor(runif(200, 1e5, 1e6)) 
item3 =  IRanges(item2, width=100)
rowRanges <- GRanges(item1,item3,
                     strand=sample(c("+", "-"), 200, TRUE),
                     feature_id=sprintf("ID%03d", 1:200))
colData <- DataFrame(Treatment=rep(c("ChIP", "Input"), 3),
                     row.names=LETTERS[1:6])
rse <- SummarizedExperiment(assays=SimpleList(counts=counts),
                            rowRanges=rowRanges, colData=colData)
```

```{r}
# For a complete workflow example demonstrating each step in the 'diffcyt' pipeline, 
# see the package vignette.

# Function to create random data (one sample)
d_random <- function(n = 20000, mean = 0, sd = 1, ncol = 20, cofactor = 5) {
  d <- sinh(matrix(rnorm(n, mean, sd), ncol = ncol)) * cofactor
  colnames(d) <- paste0("marker", sprintf("%02d", 1:ncol))
  d
}

# Create random data (without differential signal)
set.seed(123)
d_input <- list(
  sample1 = d_random(), 
  sample2 = d_random(), 
  sample3 = d_random(), 
  sample4 = d_random()
)

experiment_info <- data.frame(
  sample_id = factor(paste0("sample", 1:4)), 
  group_id = factor(c("group1", "group1", "group2", "group2")), 
  stringsAsFactors = FALSE
)

marker_info <- data.frame(
  channel_name = paste0("channel", sprintf("%03d", 1:20)), 
  marker_name = paste0("marker", sprintf("%02d", 1:20)), 
  marker_class = factor(c(rep("type", 10), rep("state", 10)), 
                        levels = c("type", "state", "none")), 
  stringsAsFactors = FALSE
)

# Prepare data
d_se <- prepareData(d_input, experiment_info, marker_info)
```

## DCATS

```{r}
K <- 2
totals1 = c(100, 800, 1300, 600)
totals2 = c(250, 700, 1100)
diri_s1 = rep(1, K) * 20
diri_s2 = rep(1, K) * 20
confuse_rate = 0.2
simil_mat = diag(K) * (1 - confuse_rate) + confuse_rate * (1 - diag(K)) / 3
sim_dat <- DCATS::simulator_base(totals1, totals2, diri_s1, diri_s2, simil_mat)
dcats_fit(sim_dat[[1]], sim_dat[[2]], confuse_mat, n_samples = 100)
```

```{r}
## betabinLRT
K <- 2
totals1 = c(100, 800, 1300, 600)
totals2 = c(250, 700, 1100)
diri_s1 = rep(1, K) * 20
diri_s2 = rep(1, K) * 20
simil_mat = get_similarity_mat(K, confuse_rate=0.2)
sim_dat <- DCATS::simulator_base(totals1, totals2, diri_s1, diri_s2, simil_mat)
DCATS::betabinLRT(sim_dat[[1]], sim_dat[[2]])
```

```{r}
## betabinLRT with bias correction
K <- 2
totals1 = c(100, 800, 1300, 600)
totals2 = c(250, 700, 1100)
diri_s1 = rep(1, K) * 20
diri_s2 = rep(1, K) * 20
simil_mat = get_similarity_mat(K, confuse_rate=0.2)
sim_dat <- DCATS::simulator_base(totals1, totals2, diri_s1, diri_s2, simil_mat)
dcats_fit(sim_dat[[1]], sim_dat[[2]], simil_mat, n_samples = 100)
```

```{r}
## multinom_EM
X = c(100, 300, 1500, 500, 1000)
simMM = get_similarity_mat(5, confuse_rate=0.2)
X * multinom_EM(X, simMM, verbose = FALSE)$mu
```


## scDC

```{r}
library(scdney)
```

```{r}
data("sim") # sample data in the vignette
exprsMat <- sim$sim_exprsMat
subject <- sim$sim_subject
cellTypes <- sim$sim_cellTypes
cond <- sim$sim_cond
```

```{r}
dim(exprsMat)
# 500 genes 260 cells
table(subject, cellTypes)
table(cond, cellTypes)
```

Perform scDC (without clustering)

```{r}
data(GSE82187.sample)
mat <- GSE82187

mat <- log2(mat+1)

# set number of clusters (classes defined in colnames)
nCs <- length(table(colnames(mat)))

# SIMLR
simlr.result <- scClust(mat, nCs, similarity = "pearson", method = "simlr", seed = 1, cores.ratio = 0)

# K-means
kmeans.result <- scClust(mat, nCs, similarity = "pearson", method = "kmeans", seed = 1, nstart = 10, iter.max = 10)
```


```{r}
res_scDC_noClust <- scDC_noClustering(cellTypes, subject, calCI = TRUE, 
                                     calCI_method = c("percentile", "BCa", "multinom"),
                                     nboot = 50)
```
Visualization

```{r}
barplotCI(res_scDC_noClust, c("cond1","cond1","cond1","cond1",
                              "cond2","cond2","cond2","cond2"))
```

```{r}
densityCI(res_scDC_noClust, c("cond1","cond1","cond1","cond1",
                              "cond2","cond2","cond2","cond2"))
```

```{r}
#sessionInfo()
source("glm.R")
res_GLM <- fitGLM_fixed(res_scDC_noClust, c("cond1","cond1","cond1","cond1","cond2","cond2","cond2","cond2"), 
                  pairwise = FALSE, fixed_only = TRUE)
res_GLM$fit_fixed
```

with clustering

```{r}
res_scDC_clust = scDC_clustering(exprsMat, cellTypes, 
                                   subject, calCI = TRUE, 
                                   calCI_method = c("percentile", "BCa", "multinom"))
```

## splatter

```{r}
library(splatter)
library(scater)
```

```{r}
library(SingleCellExperiment)
counts <- matrix(rpois(100, lambda = 10), ncol=10, nrow=10)
sce <- SingleCellExperiment(counts)
sce
```

```{r}
set.seed(1)
sce <- mockSCE()

params <- splatEstimate(sce)
params
```

## Seurat

```{r}
library(Seurat)
library(SeuratData)
InstallData("panc8")
```

```{r}
data("panc8")
pancreas.list <- SplitObject(panc8, split.by = "tech")
pancreas.list <- pancreas.list[c("celseq", "celseq2", "fluidigmc1", "smartseq2")]
```

## fastMNN

```{r}
library(Seurat)
library(SeuratData)
library(SeuratWrappers)

InstallData("pbmcsca")
data("pbmcsca")
pbmcsca <- NormalizeData(pbmcsca)
pbmcsca <- FindVariableFeatures(pbmcsca)
pbmcsca <- RunFastMNN(object.list = SplitObject(pbmcsca, split.by = "Method"))
pbmcsca <- RunUMAP(pbmcsca, reduction = "mnn", dims = 1:30)
pbmcsca <- FindNeighbors(pbmcsca, reduction = "mnn", dims = 1:30)
pbmcsca <- FindClusters(pbmcsca)
DimPlot(pbmcsca, group.by = c("Method", "ident", "CellType"), ncol = 3)
```


```{r}
library(scRNAseq)
sce <- GrunPancreasData()
print(sce)
```

```{r}
library(scuttle)
qcstats <- perCellQCMetrics(sce)
qcfilter <- quickPerCellQC(qcstats, percent_subsets="altexps_ERCC_percent")
sce <- sce[,!qcfilter$discard]
summary(qcfilter$discard)
```

```{r}
library(scran)
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, clusters=clusters)
summary(sizeFactors(sce))
sce2 <- computeSpikeFactors(sce, "ERCC")
summary(sizeFactors(sce2))
sce <- logNormCounts(sce)
```

```{r}
dec <- modelGeneVar(sce)
plot(dec$mean, dec$total, xlab="Mean log-expression", ylab="Variance")
curve(metadata(dec)$trend(x), col="blue", add=TRUE)
## with spike-ins
dec2 <- modelGeneVarWithSpikes(sce, 'ERCC')
plot(dec2$mean, dec2$total, xlab="Mean log-expression", ylab="Variance")
points(metadata(dec2)$mean, metadata(dec2)$var, col="red")
curve(metadata(dec2)$trend(x), col="blue", add=TRUE)
```

```{r}
dec3 <- modelGeneVar(sce, block=sce$donor)
per.block <- dec3$per.block
par(mfrow=c(3, 2))
for (i in seq_along(per.block)) {
    decX <- per.block[[i]]
    plot(decX$mean, decX$total, xlab="Mean log-expression", 
        ylab="Variance", main=names(per.block)[i])
    curve(metadata(decX)$trend(x), col="blue", add=TRUE)
}
```

## ROCR

```{r}
library(ROCR)
data(ROCR.simple)
df <- data.frame(ROCR.simple)
pred <- prediction(df$predictions, df$labels)
perf <- performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)
```

```{r}
# Create a basic roc object
data(aSAH)
rocobj <- roc(aSAH$outcome, aSAH$s100b)
rocobj2 <- roc(aSAH$outcome, aSAH$wfns)

library(ggplot2)
g <- ggroc(rocobj)
g
# with additional aesthetics:
ggroc(rocobj, alpha = 0.5, colour = "red", linetype = 2, size = 2)

# You can then your own theme, etc.
g + theme_minimal() + ggtitle("My ROC curve") + 
    geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="grey", linetype="dashed")

# And change axis labels to FPR/FPR
gl <- ggroc(rocobj, legacy.axes = TRUE)
gl
gl + xlab("FPR") + ylab("TPR") + 
    geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="darkgrey", linetype="dashed")

# Multiple curves:
g2 <- ggroc(list(s100b=rocobj, wfns=rocobj2, ndka=roc(aSAH$outcome, aSAH$ndka)))
g2

# This is equivalent to using roc.formula:
roc.list <- roc(outcome ~ s100b + ndka + wfns, data = aSAH)
g.list <- ggroc(roc.list)
g.list

# with additional aesthetics:
g3 <- ggroc(roc.list, linetype=2)
g3
g4 <- ggroc(roc.list, aes="linetype", color="red")
g4
# changing multiple aesthetics:
g5 <- ggroc(roc.list, aes=c("linetype", "color"))
g5

# OR faceting
g.list + facet_grid(.~name) + theme(legend.position="none")
# To have all the curves of the same color, use aes="group":
g.group <- ggroc(roc.list, aes="group")
g.group
g.group + facet_grid(.~name)
```

## DCATS_GLM

```{r}
library(DCATS)
```

```{r}
dcats_GLM <- function(count_mat, design_mat, model='betabin', base_model='NULL') {
  # Output matrices
  coeffs     <- matrix(NA, ncol(count_mat), ncol(design_mat))
  coeffs_err <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LR_vals    <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LRT_pvals  <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LRT_fdr    <- matrix(NA, ncol(count_mat), ncol(design_mat))

  # Check colnames
  if (is.null(colnames(count_mat)))
    colnames(count_mat) <- paste0('cell_type_', seq(ncol(count_mat)))
  if (is.null(colnames(design_mat)))
    colnames(design_mat) <- paste0('factor_', seq(ncol(design_mat)))

  # Add rownames and colnames
  rownames(LR_vals) <- rownames(LRT_pvals) <- rownames(LRT_fdr) <-
    rownames(coeffs) <- rownames(coeffs_err) <- colnames(count_mat)
  colnames(LR_vals) <- colnames(LRT_pvals) <- colnames(LRT_fdr) <-
    colnames(coeffs) <- colnames(coeffs_err) <- colnames(design_mat)

  # Test each factor
  for (m in seq_len(ncol(count_mat))) {
    for (k in seq_len(ncol(design_mat))) {
      df_use <- data.frame(n1 = count_mat[, m], total=rowSums(count_mat))
      df_use <- cbind(df_use, as.data.frame(design_mat)[, k, drop=FALSE])

      df_tmp <- df_use[!is.na(design_mat[, k]), ]

      if (model == 'betabin') {
        fm0 <- aod::betabin(cbind(n1, total-n1) ~ 1, ~ 1, data = df_tmp)

        formula_fix <- as.formula(paste0('cbind(n1, total-n1)', '~ 1+',
                                         colnames(design_mat)[k], sep=''))
        fm1 <- aod::betabin(formula_fix, ~ 1, data = df_tmp)
      } else {
        fm0 <- aod::negbin(n1 ~ total + 1, ~ 1, data = df_tmp)

        formula_fix <- as.formula(paste0('n1 ~  ', colnames(design_mat)[k],
                                         '+ total + 1', sep=''))
        fm1 <- aod::negbin(formula_fix, ~ 1, data = df_tmp)
      }

      ## ignore the fitting if the hessian matrix is singular
      if (length(fm1@varparam) < 4 || is.na(fm1@varparam[2, 2])) {next}

      LR_vals[m, k] <- fm0@dev - fm1@dev
      LRT_pvals[m, k] <- pchisq(LR_vals[m, k], df=1, lower.tail = FALSE, log.p = FALSE)

      coeffs[m, k] <- fm1@param[2]
      coeffs_err[m, k] <- fm1@varparam[2, 2]
    }
  }

  # Return list
  LRT_fdr[,] <- p.adjust(LRT_pvals, method = 'fdr')
  res <- list('ceoffs'=coeffs, 'coeffs_err'=coeffs_err,
              'LR_vals'=LR_vals, 'pvals'=LRT_pvals, 'fdr'=LRT_fdr)
  res
}
```

```{r}
count_mat = matrix(1:12, ncol = 3)
design_mat = matrix(head(LETTERS, 12), ncol = 3)
```

