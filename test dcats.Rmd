---
title: "Test dcats_GLM"
author: "Xinyi Lin"
date: "7/20/2021"
output: html_document
---

The function used: 

```{r}
dcats_GLM <- function(count_mat, design_mat, similarity_mat=NULL, n_samples=50, pseudo_count=NULL, intercept = TRUE,  base_model='NULL') {
  # Output matrices
  coeffs     <- matrix(NA, ncol(count_mat), ncol(design_mat))
  coeffs_err <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LR_vals    <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LRT_pvals  <- matrix(NA, ncol(count_mat), ncol(design_mat))
  pvals  <- matrix(NA, ncol(count_mat), ncol(design_mat))
  LRT_fdr    <- matrix(NA, ncol(count_mat), ncol(design_mat))
  
  # Check colnames
  if (is.null(colnames(count_mat)))
    colnames(count_mat) <- paste0('cell_type_', seq(ncol(count_mat)))
  if (is.null(colnames(design_mat)))
    colnames(design_mat) <- paste0('factor_', seq(ncol(design_mat)))
  
  # Add rownames and colnames
  rownames(LR_vals) <- rownames(LRT_pvals) <- rownames(pvals) <- rownames(LRT_fdr) <-
    rownames(coeffs) <- rownames(coeffs_err) <- colnames(count_mat)
  colnames(LR_vals) <- colnames(LRT_pvals) <- colnames(pvals) <- colnames(LRT_fdr) <-
    colnames(coeffs) <- colnames(coeffs_err) <- colnames(design_mat)
  
  
  ## using estimated the latent cell counts
  count_latent = count_mat
  if(!is.null(similarity_mat)) {
    for (i in seq_len(nrow(count_mat))) {
      count_latent[i, ] <- sum(count_mat[i, ]) *
        multinom_EM(count_mat[i, ], similarity_mat, verbose = FALSE)$mu
    }
  }
  
  K <- ncol(count_mat) ## number of cell types
  if (is.null(similarity_mat)) {
    n_samples <- 1
  }
  
  if (!is.null(n_samples) && !is.null(similarity_mat)) {
    count_use <- matrix(0, nrow(count_mat) * n_samples, K)
    for (i in seq_len(nrow(count_mat))) {
      idx <- seq((i - 1) * n_samples + 1, i * n_samples)
      for (j in seq_len(K)) {
        count_use[idx, ] <- (
          count_use[idx, ] + t(rmultinom(n_samples, count_latent[i, j], similarity_mat[j, ])))
      }
    }
  } else{
    count_use <- count_mat
  }
  
  # adding pseudo counts
  if (is.null(pseudo_count)) {
    if (any(colMeans(count_mat) == 0)) {
      print(paste("Empty cell type exists in at least one conidtion;",
                  "adding replicate & condition specific pseudo count:"))
      count_use <- count_use + 1
    }
  } else {
    count_use = count_use + pseudo_count
  }
  
  count_use = round(count_use)
  
  # Test each factor
  for (k in seq_len(ncol(design_mat))) {    ## for each factor
    sub_LR_val <- matrix(NA, n_samples, K)
    sub_coeffs_val <- matrix(NA, n_samples, K)
    sub_coeffs_err <- matrix(NA, n_samples, K)
    for (ir in seq_len(n_samples)) {          ## for each sampling
      for (m in seq_len(ncol(count_use))) {       ## for each cluster
        idx <- seq(1, nrow(count_use), n_samples) + ir - 1
        
        df_use <- data.frame(n1 = count_use[, m], total=rowSums(count_use))[idx,]
        df_use <- cbind(df_use, design_mat)
        df_tmp <- df_use[!is.na(design_mat[, k]), ]
        
        ## model fitting using betabin
        if (base_model=='NULL' | ncol(design_mat) == 1) {
          fm0 <- aod::betabin(cbind(n1, total-n1) ~ 1, ~ 1, data = df_tmp)
          #formula_fix <- as.formula(paste0('cbind(n1, total-n1)', '~ 1+', colnames(design_mat)[k], sep=''))
          formula_fix <- as.formula(paste0('cbind(n1, total-n1)', ' ~ ', colnames(design_mat)[k], sep=''))
          fm1 <- aod::betabin(formula_fix, ~ 1, data = df_tmp, warnings = FALSE)
        } else if (base_model=='FULL') {
          fm0_right <- paste(colnames(design_mat)[-k], collapse = " + ")
          fm1_right <- paste(colnames(design_mat), collapse = " + ")
          if (isTRUE(intercept)){
            formula_fm0 <- as.formula(paste0('cbind(n1, total-n1)', ' ~ 1 + ', fm0_right, sep=''))
            fm0 <- aod::betabin(formula_fm0, ~ 1, data = df_tmp, warnings = FALSE)
            formula_fm1 <- as.formula(paste0('cbind(n1, total-n1)', ' ~ 1 + ', fm1_right, sep=''))
            fm1 <- aod::betabin(formula_fm1, ~ 1, data = df_tmp, warnings = FALSE)
          } else {
            formula_fm0 <- as.formula(paste0('cbind(n1, total-n1)', ' ~ ', fm0_right, sep=''))
            fm0 <- aod::betabin(formula_fm0, ~ 1, data = df_tmp, warnings = FALSE)
            formula_fm1 <- as.formula(paste0('cbind(n1, total-n1)', ' ~ ', fm1_right, sep=''))
            fm1 <- aod::betabin(formula_fm1, ~ 1, data = df_tmp, warnings = FALSE)
          }
        }
        
        ## ignore the fitting if the hessian matrix is singular
        if (length(fm1@varparam) < 4 || is.na(fm1@varparam[2, 2])) {next}
        
        sub_LR_val[ir, m] <- fm0@dev - fm1@dev
        sub_coeffs_val[ir, m] <- fm1@param[2]
        sub_coeffs_err[ir, m] <-fm1@varparam[2, 2]
      }
    }
    ## averaging the estimation to get the final result
    if (is.null(n_samples) || is.null(similarity_mat) || n_samples == 1){
      sub_coeff_err_pool <- colMeans(sub_coeffs_err**2, na.rm = TRUE)
    } else {
      sub_coeff_err_pool <- colMeans(sub_coeffs_err**2, na.rm = TRUE) +
        matrixStats::colSds(sub_coeffs_val) +
        matrixStats::colSds(sub_coeffs_val) / n_samples
    }
    coeff_val_mean <- colMeans(sub_coeffs_val, na.rm = TRUE)
    LR_median = robustbase::colMedians(sub_LR_val, na.rm = TRUE)
    
    # p values with Ward test: https://en.wikipedia.org/wiki/Wald_test
    pvals[,k] <- pnorm(-abs(coeff_val_mean) / sqrt(sub_coeff_err_pool))  * 2
    LR_vals[, k] <- LR_median
    LRT_pvals[, k] <- pchisq(LR_median, df=1, lower.tail = FALSE, log.p = FALSE)
    coeffs[, k] <- coeff_val_mean
    coeffs_err[, k] <- sqrt(sub_coeff_err_pool)
  }
  
  # Return list
  LRT_fdr[,] <- p.adjust(LRT_pvals, method = 'fdr')
  res <- list('ceoffs'=coeffs, 'coeffs_err'=coeffs_err, 'pvals' = pvals, 'LR_vals'=LR_vals, 'LRT_pvals'=LRT_pvals, 'fdr'=LRT_fdr)
  res
}
```

```{r}
library(DCATS)
library(fastDummies)
library(tidyverse)
```

```{r}
Kaufmann2021 = read.delim(gzfile(str_c(pathSPC, "/DCATS/Kaufmann2021_metadata_per_cell.csv.gz")), sep = ",") %>% 
  janitor::clean_names() %>% 
  mutate_if(is.character, as.factor)
head(Kaufmann2021)
summary(Kaufmann2021)
Kaufmann2021 %>% group_by(group) %>% 
  summarise(donor = unique(donor)) %>% 
  summarise(n = n())
```

## treated vs untreated

should give positive result for T09&T06 -> wrong

```{r}
res_mat = Kaufmann2021 %>% filter(group == "MS1_nat" | group == "MS1") %>% 
  group_by(donor, cluster_names, sex, age_sampling, natalizumab_treatment) %>% 
  summarise(n = n()) %>% 
  pivot_wider(names_from = cluster_names, values_from = n) %>% 
  replace(is.na(.), 0) %>% 
  mutate(sample = str_c(donor, "_", natalizumab_treatment)) %>% 
  column_to_rownames("sample")
res_mat %>% print()
```

```{r}
count_mat = res_mat %>% select(B01:T11) %>% 
  as.matrix()
design_mat = res_mat %>% select(donor:natalizumab_treatment) %>% 
  dummy_cols(select_columns = "donor") %>% 
  select(donor, age_sampling, natalizumab_treatment, str_c("donor_", res_mat$donor)) %>% 
  #select(donor, sex, age_sampling, natalizumab_treatment, str_c("donor_", res_mat$donor)) %>% 
  mutate(donor = str_c(donor, "_", natalizumab_treatment)) %>% 
  column_to_rownames("donor") %>% 
  janitor::clean_names() %>% 
  select(-donor_hh_ox_31, -donor_hh_ox_23)
  
print(count_mat)
print(design_mat)

simil_mat = create_simMat(dim(count_mat)[2], confuse_rate=0.1)
res_GLM = dcats_GLM(count_mat = count_mat, design_mat = design_mat, similarity_mat = simil_mat, intercept = FALSE, base_model = "FULL")
sig_GLM = ifelse(res_GLM$LRT_pvals < 0.05, "P", "N") 
print(sig_GLM)
print(res_GLM$LRT_pvals)
print(res_GLM$pvals)
```

## test add fix phi

```{r}

```

